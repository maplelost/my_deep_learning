{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念\n",
    "在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在⼤多数情况是“可优化”的，我们称之为<font color=red>⽬标函数（objective function）</font>。我们通常定义⼀个⽬标函数，并希望优化它到最低点。因为越低越好，所以这些函数有时被称为<font color=red>损失函数（loss function, 或cost function）</font>。但这只是⼀个惯例，你也可以取⼀个新的函数，优化到它的最⾼点。这两个函数本质上是相同的，只是翻转⼀下符号。\n",
    "\n",
    "  <font color=green>当任务为试图预测数值时，最常⻅的损失函数是平⽅误差（squared error），即预测值与实际值之差的平⽅。\n",
    "当试图解决分类问题时，最常⻅的⽬标函数是最小化错误率，即预测与实际情况不符的样本⽐例。有些⽬标\n",
    "函数（如平⽅误差）很容易被优化，有些⽬标（如错误率）由于不可微性或其他复杂性难以直接优化。在这\n",
    "些情况下，通常会优化替代⽬标。</font>\n",
    "\n",
    "损失函数是根据模型参数定义的，并取决于数据集。在⼀个数据集上，我们通过最小化总损失来学习\n",
    "模型参数的最佳值。该数据集由⼀些为训练而收集的样本组成，<font color=red>称为训练数据集（training dataset，或称为\n",
    "训练集（training set））。</font>\n",
    "\n",
    "当⼀个模型在训练集上表现良好，但不能推⼴到测试集时，我们说这个模型是<font color=red>“过拟合”（overfitting）</font>的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⼀旦我们获得了⼀些数据源及其表⽰、⼀个模型和⼀个合适的损失函数，我们接下来就需要⼀种算法，它能\n",
    "够搜索出最佳参数，以最小化损失函数。深度学习中，⼤多流⾏的优化算法通常基于⼀种基本⽅法‒<font color=red>梯度下降（gradient descent）。</font>在每个步骤中，梯度下降法都会检查每个参数，看看如果你仅对该参数进⾏\n",
    "少量变动，训练集损失会朝哪个⽅向移动。然后，它在可以减少损失的⽅向上优化参数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 监督学习\n",
    "<font color=red>监督学习（supervised learning）</font>擅⻓在“给定输⼊特征”的情况下预测标签。\n",
    "\n",
    "即我们向模型提供巨⼤数据集：每个样本包含特征和相应标签值。\n",
    "### 回归\n",
    "<font color=green>\n",
    "回归（regression）是最简单的监督学习任务之⼀。</font>\n",
    "总而⾔之，判断回归问题的⼀个很好的经验法则是，\n",
    "任何有关“多少”的问题很可能就是回归问题。\n",
    "\n",
    "### 分类\n",
    "在分类问题中，我们希望\n",
    "模型能够预测样本属于哪个<font color=blue>类别（category，正式称为类（class））。</font>\n",
    "\n",
    "在回归中，我们训练⼀个回归函数来输出⼀个数值；而在分类中，我们训练⼀个分类器，它的输出即为预测的类别。\n",
    "与解决回归问题不同，分类问题的常⻅损失函数被称为交叉熵（cross-entropy）\n",
    "\n",
    "我们宁愿错误地分⼊⼀个相关\n",
    "的类别，也不愿错误地分⼊⼀个遥远的类别，这通常被称为层次分类(hierarchical classification)。\n",
    "### 标记问题\n",
    "学习预测不相互排斥的类别的问题称为<font color=red>多标签分类（multilabel classification）。</font>\n",
    "### 搜索\n",
    "有时，我们不仅仅希望输出为⼀个类别或⼀个实值。例如在信息检索领域，我们希望有用的信息排序在最前面。\n",
    "### 推荐系统\n",
    "另⼀类与搜索和排名相关的问题是推荐系统（recommender system），它的⽬标是向给特定⽤⼾进⾏“个性化”推荐。\n",
    "\n",
    "推荐系统有可能形成反馈循环：推荐系统⾸先会优先推送⼀个购买\n",
    "量较⼤（可能被认为更好）的商品，然而⽬前⽤⼾的购买习惯往往是遵循推荐算法，但学习算法并不总是考\n",
    "虑到这⼀细节，进而更频繁地被推荐。\n",
    "### 序列学习\n",
    "不具有固定⼤小的输⼊和产⽣固定⼤小的输出。\n",
    "\n",
    "例子：标记和解析，⽂本到语⾳，⾃动语⾳识别，机器翻译。\n",
    "## 1.3.2 ⽆监督学习\n",
    "我们称这类数据中不含有“⽬标”的机器学习问题为<font color=red>⽆监督学习（unsupervised learning）</font>\n",
    "聚类（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？⽐如，给定⼀组照⽚，我们\n",
    "能把它们分成⻛景照⽚、狗、婴⼉、猫和⼭峰的照⽚吗？同样，给定⼀组⽤⼾的⽹⻚浏览记录，我们能否将具有相似⾏为的⽤⼾聚类吗？\n",
    "\n",
    "主成分分析（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？\n",
    "\n",
    "因果关系（causality）和概率图模型（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和⼯资的⼈口统计数据，我们能否简单地根据经验数据发现它们之间的关系？\n",
    "\n",
    " ⽣成对抗性⽹络（generative adversarial networks）：为我们提供⼀种合成数据的⽅法，甚⾄像图像和⾳频这样复杂的结构化数据。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
